{
    "sourceFile": "tests/realtimestt_speechendpoint_binary_classified.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1757303957577,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1757303957577,
            "name": "Commit-0",
            "content": "\n# IS_DEBUG = True\nIS_DEBUG = False\nUSE_STEREO_MIX = True\nLOOPBACK_DEVICE_NAME = \"Microphone (H Series Stereo Track Usb Audio)\"\nLOOPBACK_DEVICE_HOST_API = 2\n\nimport os\nimport re\nimport sys\nimport threading\nimport queue\nimport time\nfrom collections import deque\nfrom difflib import SequenceMatcher\nfrom install_packages import check_and_install_packages\n\n# Ensure local repository version of RealtimeSTT is imported (not a pip cached older wheel)\nREPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\nif REPO_ROOT not in sys.path:\n    sys.path.insert(0, REPO_ROOT)\n\n# Check and install required packages\ncheck_and_install_packages(\n    [\n        {\"import_name\": \"rich\"},\n        {\"import_name\": \"colorama\"},\n        # Skip installing RealtimeSTT from PyPI to avoid overwriting local dev version\n        {\"import_name\": \"transformers\"},\n        {\"import_name\": \"torch\"},\n        {\"import_name\": \"onnx_asr\", \"package_name\": \"onnx-asr[gpu,hub]\"},\n    ]\n)\n\nEXTENDED_LOGGING = False\nsentence_end_marks = [\".\", \"!\", \"?\", \"ã€‚\"]\n\n\ndetection_speed = 2.0  # set detection speed between 0.1 and 2.0\n\n\nif detection_speed < 0.1:\n    detection_speed = 0.1\nif detection_speed > 2.5:\n    detection_speed = 2.5\n\nlast_detection_pause = 0\nlast_prob_complete = 0\nlast_suggested_pause = 0\nlast_pause = 0\nunknown_sentence_detection_pause = 1.8\nellipsis_pause = 4.5\npunctuation_pause = 0.4\nexclamation_pause = 0.3\nquestion_pause = 0.2\n\nhard_break_even_on_background_noise = 6\nhard_break_even_on_background_noise_min_texts = 3\nhard_break_even_on_background_noise_min_chars = 15\nhard_break_even_on_background_noise_min_similarity = 0.99\n\nif __name__ == \"__main__\":\n\n    if EXTENDED_LOGGING:\n        import logging\n\n        logging.basicConfig(level=logging.DEBUG)\n\n    from rich.console import Console\n    from rich.live import Live\n    from rich.text import Text\n    from rich.panel import Panel\n\n    console = Console()\n    console.print(\"System initializing, please wait\")\n\n    from RealtimeSTT import AudioToTextRecorder\n    from colorama import Fore, Style\n    import colorama\n\n    import torch\n    import torch.nn.functional as F\n    from transformers import (\n        DistilBertTokenizerFast,\n        DistilBertForSequenceClassification,\n    )\n\n    # Load classification model\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_dir = \"KoljaB/SentenceFinishedClassification\"\n    max_length = 128\n\n    tokenizer = DistilBertTokenizerFast.from_pretrained(model_dir)\n    classification_model = DistilBertForSequenceClassification.from_pretrained(\n        model_dir\n    )\n    classification_model.to(device)\n    classification_model.eval()\n\n    # Label mapping\n    label_map = {0: \"Incomplete\", 1: \"Complete\"}\n\n    # We now want probabilities, not just a label\n    def get_completion_probability(sentence, model, tokenizer, device, max_length):\n        \"\"\"\n        Return the probability that the sentence is complete.\n        \"\"\"\n        inputs = tokenizer(\n            sentence,\n            return_tensors=\"pt\",\n            truncation=True,\n            padding=\"max_length\",\n            max_length=max_length,\n        )\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        logits = outputs.logits\n        probabilities = F.softmax(logits, dim=1).squeeze().tolist()\n        # probabilities is [prob_incomplete, prob_complete]\n        # We want the probability of being complete\n        prob_complete = probabilities[1]\n        return prob_complete\n\n    # We have anchor points for probability to detection mapping\n    # (probability, rapid_sentence_end_detection)\n    anchor_points = [(0.0, 1.0), (1.0, 0)]\n\n    def interpolate_detection(prob):\n        # Clamp probability between 0.0 and 1.0 just in case\n        p = max(0.0, min(prob, 1.0))\n        # If exactly at an anchor point\n        for ap_p, ap_val in anchor_points:\n            if abs(ap_p - p) < 1e-9:\n                return ap_val\n\n        # Find where p fits\n        for i in range(len(anchor_points) - 1):\n            p1, v1 = anchor_points[i]\n            p2, v2 = anchor_points[i + 1]\n            if p1 <= p <= p2:\n                # Linear interpolation\n                ratio = (p - p1) / (p2 - p1)\n                return v1 + ratio * (v2 - v1)\n\n        # Should never reach here if anchor_points cover [0,1]\n        return 4.0\n\n    speech_finished_cache = {}\n\n    def is_speech_finished(text):\n        # Returns a probability of completeness\n        # Use cache if available\n        if text in speech_finished_cache:\n            return speech_finished_cache[text]\n\n        prob_complete = get_completion_probability(\n            text, classification_model, tokenizer, device, max_length\n        )\n        speech_finished_cache[text] = prob_complete\n        return prob_complete\n\n    if os.name == \"nt\" and (3, 8) <= sys.version_info < (3, 99):\n        from torchaudio._extension.utils import _init_dll_path\n\n        _init_dll_path()\n\n    colorama.init()\n\n    live = Live(console=console, refresh_per_second=10, screen=False)\n    live.start()\n\n    text_queue = queue.Queue()\n\n    full_sentences = []\n    rich_text_stored = \"\"\n    recorder = None\n    displayed_text = \"\"\n    text_time_deque = deque()\n    texts_without_punctuation = []\n    relisten_on_abrupt_stop = True\n    abrupt_stop = False\n    prev_text = \"\"\n\n    def preprocess_text(text):\n        text = text.lstrip()\n        if text.startswith(\"...\"):\n            text = text[3:]\n        text = text.lstrip()\n        if text:\n            text = text[0].upper() + text[1:]\n        return text\n\n    def text_detected(text):\n        text_queue.put(text)\n\n    def ends_with_string(text: str, s: str):\n        if text.endswith(s):\n            return True\n        if len(text) > 1 and text[:-1].endswith(s):\n            return True\n        return False\n\n    def sentence_end(text: str):\n        if text and text[-1] in sentence_end_marks:\n            return True\n        return False\n\n    def additional_pause_based_on_words(text):\n        word_count = len(text.split())\n        pauses = {\n            0: 0.35,\n            1: 0.3,\n            2: 0.25,\n            3: 0.2,\n            4: 0.15,\n            5: 0.1,\n            6: 0.05,\n        }\n        return pauses.get(word_count, 0.0)\n\n    def strip_ending_punctuation(text):\n        \"\"\"Remove trailing periods and ellipses from text.\"\"\"\n        text = text.rstrip()\n        for char in sentence_end_marks:\n            text = text.rstrip(char)\n        return text\n\n    def get_suggested_whisper_pause(text):\n        if ends_with_string(text, \"...\"):\n            return ellipsis_pause\n        elif ends_with_string(text, \".\"):\n            return punctuation_pause\n        elif ends_with_string(text, \"!\"):\n            return exclamation_pause\n        elif ends_with_string(text, \"?\"):\n            return question_pause\n        else:\n            return unknown_sentence_detection_pause\n\n    def find_stereo_mix_index():\n        import pyaudio\n\n        audio = pyaudio.PyAudio()\n        devices_info = \"\"\n        for i in range(audio.get_device_count()):\n            dev = audio.get_device_info_by_index(i)\n            devices_info += (\n                f\"{dev['index']}: {dev['name']} (hostApi: {dev['hostApi']})\\n\"\n            )\n\n            if (\n                LOOPBACK_DEVICE_NAME.lower() in dev[\"name\"].lower()\n                and dev[\"hostApi\"] == LOOPBACK_DEVICE_HOST_API\n            ):\n                return dev[\"index\"], devices_info\n\n        return None, devices_info\n\n    def find_matching_texts(texts_without_punctuation):\n        \"\"\"\n        Find entries where text_without_punctuation matches the last entry,\n        going backwards until the first non-match is found.\n\n        Args:\n            texts_without_punctuation: List of tuples (original_text, stripped_text)\n\n        Returns:\n            List of tuples (original_text, stripped_text) matching the last entry's stripped text,\n            stopping at the first non-match\n        \"\"\"\n        if not texts_without_punctuation:\n            return []\n\n        # Get the stripped text from the last entry\n        last_stripped_text = texts_without_punctuation[-1][1]\n\n        matching_entries = []\n\n        # Iterate through the list backwards\n        for entry in reversed(texts_without_punctuation):\n            original_text, stripped_text = entry\n\n            # If we find a non-match, stop\n            if stripped_text != last_stripped_text:\n                break\n\n            # Add the matching entry to our results\n            matching_entries.append((original_text, stripped_text))\n\n        # Reverse the results to maintain original order\n        matching_entries.reverse()\n\n        return matching_entries\n\n    def process_queue():\n        global recorder, full_sentences, prev_text, displayed_text, rich_text_stored, text_time_deque, abrupt_stop, rapid_sentence_end_detection, last_prob_complete, last_suggested_pause, last_pause\n        while True:\n            text = None  # Initialize text to ensure it's defined\n\n            try:\n                # Attempt to retrieve the first item, blocking with timeout\n                text = text_queue.get(timeout=1)\n            except queue.Empty:\n                continue  # No item retrieved, continue the loop\n\n            if text is None:\n                # Exit signal received\n                break\n\n            # Drain the queue to get the latest text\n            try:\n                while True:\n                    latest_text = text_queue.get_nowait()\n                    if latest_text is None:\n                        text = None\n                        break\n                    text = latest_text\n            except queue.Empty:\n                pass  # No more items to retrieve\n\n            if text is None:\n                # Exit signal received after draining\n                break\n\n            text = preprocess_text(text)\n            current_time = time.time()\n            text_time_deque.append((current_time, text))\n\n            # get text without ending punctuation\n            text_without_punctuation = strip_ending_punctuation(text)\n\n            # print(f\"Text: {text}, Text without punctuation: {text_without_punctuation}\")\n            texts_without_punctuation.append((text, text_without_punctuation))\n\n            matches = find_matching_texts(texts_without_punctuation)\n            # print(\"Texts matching the last entry's stripped version:\")\n\n            added_pauses = 0\n            contains_ellipses = False\n            for i, match in enumerate(matches):\n                same_text, stripped_punctuation = match\n                suggested_pause = get_suggested_whisper_pause(same_text)\n                added_pauses += suggested_pause\n                if ends_with_string(same_text, \"...\"):\n                    contains_ellipses = True\n\n            avg_pause = added_pauses / len(matches) if len(matches) > 0 else 0\n            suggested_pause = avg_pause\n            # if contains_ellipses:\n            #     suggested_pause += ellipsis_pause / 2\n\n            prev_text = text\n            import string\n\n            transtext = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n\n            # **Stripping Trailing Non-Alphabetical Characters**\n            # Instead of removing all punctuation, we only strip trailing non-alphabetic chars.\n            # Use regex to remove trailing non-alphabetic chars:\n            cleaned_for_model = re.sub(r\"[^a-zA-Z]+$\", \"\", transtext)\n\n            prob_complete = is_speech_finished(cleaned_for_model)\n\n            # Interpolate rapid_sentence_end_detection based on prob_complete\n            new_detection = interpolate_detection(prob_complete)\n\n            # pause = new_detection + suggested_pause\n            pause = (new_detection + suggested_pause) * detection_speed\n\n            # **Add Additional Pause Based on Word Count**\n            # extra_pause = additional_pause_based_on_words(text)\n            # pause += extra_pause  # Add the extra pause to the total pause duration\n\n            # Optionally, you can log this information for debugging\n            if IS_DEBUG:\n                print(\n                    f\"Prob: {prob_complete:.2f}, \"\n                    f\"whisper {suggested_pause:.2f}, \"\n                    f\"model {new_detection:.2f}, \"\n                    # f\"extra {extra_pause:.2f}, \"\n                    f\"final {pause:.2f} | {transtext} \"\n                )\n\n            recorder.post_speech_silence_duration = pause\n\n            # Remove old entries\n            while (\n                text_time_deque\n                and text_time_deque[0][0]\n                < current_time - hard_break_even_on_background_noise\n            ):\n                text_time_deque.popleft()\n\n            # Check for abrupt stops (background noise)\n            if len(text_time_deque) >= hard_break_even_on_background_noise_min_texts:\n                texts = [t[1] for t in text_time_deque]\n                first_text = texts[0]\n                last_text = texts[-1]\n                similarity = SequenceMatcher(None, first_text, last_text).ratio()\n\n                if (\n                    similarity > hard_break_even_on_background_noise_min_similarity\n                    and len(first_text) > hard_break_even_on_background_noise_min_chars\n                ):\n                    abrupt_stop = True\n                    recorder.stop()\n\n            rich_text = Text()\n            for i, sentence in enumerate(full_sentences):\n                style = \"yellow\" if i % 2 == 0 else \"cyan\"\n                rich_text += Text(sentence, style=style) + Text(\" \")\n\n            if text:\n                rich_text += Text(text, style=\"bold yellow\")\n\n            new_displayed_text = rich_text.plain\n\n            displayed_text = new_displayed_text\n            last_prob_complete = new_detection\n            last_suggested_pause = suggested_pause\n            last_pause = pause\n            panel = Panel(\n                rich_text,\n                title=f\"[bold green]Prob complete:[/bold green] [bold yellow]{prob_complete:.2f}[/bold yellow], pause whisper [bold yellow]{suggested_pause:.2f}[/bold yellow], model [bold yellow]{new_detection:.2f}[/bold yellow], last detection [bold yellow]{last_detection_pause:.2f}[/bold yellow]\",\n                border_style=\"bold green\",\n            )\n            live.update(panel)\n            rich_text_stored = rich_text\n\n            text_queue.task_done()\n\n    def process_text(text):\n        global recorder, full_sentences, prev_text, abrupt_stop, last_detection_pause\n        last_prob_complete, last_suggested_pause, last_pause\n        last_detection_pause = recorder.post_speech_silence_duration\n        if IS_DEBUG:\n            print(\n                f\"Model pause: {last_prob_complete:.2f}, Whisper pause: {last_suggested_pause:.2f}, final pause: {last_pause:.2f}, last_detection_pause: {last_detection_pause:.2f}\"\n            )\n        # if IS_DEBUG: print(f\"SENTENCE: post_speech_silence_duration: {recorder.post_speech_silence_duration}\")\n        recorder.post_speech_silence_duration = unknown_sentence_detection_pause\n        text = preprocess_text(text)\n        text = text.rstrip()\n        text_time_deque.clear()\n        if text.endswith(\"...\"):\n            text = text[:-2]\n\n        full_sentences.append(text)\n        prev_text = \"\"\n\n        text_detected(\"\")\n\n        if abrupt_stop:\n            abrupt_stop = False\n            if relisten_on_abrupt_stop:\n                recorder.listen()\n                recorder.start()\n                if hasattr(recorder, \"last_words_buffer\"):\n                    recorder.frames.extend(list(recorder.last_words_buffer))\n\n    recorder_config = {\n        \"spinner\": False,\n        # Use Parakeet ONNX backend for final transcription\n        \"model\": \"parakeet-tdt-0.6b-v2-onnx\",\n        \"stt_backend\": \"parakeet\",\n        \"force_threading\": True,\n        # Keep tiny Whisper realtime model for partials\n        \"realtime_model_type\": \"tiny.en\",\n        \"language\": \"en\",\n        \"silero_sensitivity\": 0.4,\n        \"webrtc_sensitivity\": 3,\n        \"post_speech_silence_duration\": unknown_sentence_detection_pause,\n        \"min_length_of_recording\": 1.1,\n        \"min_gap_between_recordings\": 0,\n        \"enable_realtime_transcription\": True,\n        \"realtime_processing_pause\": 0.05,\n        \"on_realtime_transcription_update\": text_detected,\n        \"silero_deactivity_detection\": True,\n        \"early_transcription_on_silence\": 0,\n        \"beam_size\": 5,\n        \"beam_size_realtime\": 1,\n        # Parakeet path processes whole audio; disable batching\n        \"batch_size\": 0,\n        \"realtime_batch_size\": 4,\n        \"no_log_file\": True,\n        \"initial_prompt_realtime\": (\n            \"End incomplete sentences with ellipses.\\n\"\n            \"Examples:\\n\"\n            \"Complete: The sky is blue.\\n\"\n            \"Incomplete: When the sky...\\n\"\n            \"Complete: She walked home.\\n\"\n            \"Incomplete: Because he...\\n\"\n        ),\n    }\n\n    if EXTENDED_LOGGING:\n        recorder_config[\"level\"] = logging.DEBUG\n\n    if USE_STEREO_MIX:\n        device_index, devices_info = find_stereo_mix_index()\n        if device_index is None:\n            live.stop()\n            console.print(\n                \"[bold red]Stereo Mix device not found. Available audio devices are:\\n[/bold red]\"\n            )\n            console.print(devices_info, style=\"red\")\n            sys.exit(1)\n        else:\n            recorder_config[\"input_device_index\"] = device_index\n            console.print(\n                f\"Using audio device index {device_index} for Stereo Mix.\",\n                style=\"green\",\n            )\n\n    recorder = AudioToTextRecorder(**recorder_config)\n\n    initial_text = Panel(\n        Text(\"Say something...\", style=\"cyan bold\"),\n        title=\"[bold yellow]Waiting for Input[/bold yellow]\",\n        border_style=\"bold yellow\",\n    )\n    live.update(initial_text)\n\n    worker_thread = threading.Thread(target=process_queue, daemon=True)\n    worker_thread.start()\n\n    try:\n        while True:\n            recorder.text(process_text)\n    except KeyboardInterrupt:\n        text_queue.put(None)\n        worker_thread.join()\n        live.stop()\n        console.print(\"[bold red]Transcription stopped by user. Exiting...[/bold red]\")\n        exit(0)\n"
        }
    ]
}